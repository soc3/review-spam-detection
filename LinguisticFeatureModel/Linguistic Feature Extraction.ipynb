{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linguistic Feature Detection Model\n",
    "\n",
    "## 1.Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import features\n",
    "import nltk\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/TrainingSet\") as fh:\n",
    "    data = json.load(fh)\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = [\"review_id\", \"hotel_name\", \"review\", \"polarity\", \"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Extracting linguistic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = 0\n",
    "df[\"num_of_words\"] = np.nan\n",
    "df[\"avg_words_per_sent\"]=np.nan\n",
    "df[\"unique_words\"]=np.nan\n",
    "df[\"self_words\"]=np.nan\n",
    "df[\"brand\"]=np.nan\n",
    "df[\"avg_word_length\"]=np.nan\n",
    "df[\"connectors\"]=np.nan\n",
    "df[\"digits\"]=np.nan\n",
    "df[\"verbs_per_noun\"]=np.nan\n",
    "df[\"adj\"]=np.nan\n",
    "df[\"prep\"]=np.nan\n",
    "df[\"adverb\"]=np.nan\n",
    "#Iterating through whole data-set to add linguistic features\n",
    "for review in df[\"review\"]:\n",
    "    a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12 = features.majorfunc(review)\n",
    "    df.iloc[iterator, df.columns.get_loc('num_of_words')] = a1\n",
    "    df.iloc[iterator, df.columns.get_loc('avg_words_per_sent')] = a2\n",
    "    df.iloc[iterator, df.columns.get_loc('unique_words')] = a3\n",
    "    df.iloc[iterator, df.columns.get_loc('self_words')] = a4\n",
    "    df.iloc[iterator, df.columns.get_loc('brand')] = a5\n",
    "    df.iloc[iterator, df.columns.get_loc('avg_word_length')] = a6\n",
    "    df.iloc[iterator, df.columns.get_loc('connectors')] = a7\n",
    "    df.iloc[iterator, df.columns.get_loc('digits')] = a8\n",
    "    df.iloc[iterator, df.columns.get_loc('verbs_per_noun')] = a9\n",
    "    df.iloc[iterator, df.columns.get_loc('adj')] = a10\n",
    "    df.iloc[iterator, df.columns.get_loc('prep')] = a11\n",
    "    df.iloc[iterator, df.columns.get_loc('adverb')] = a12\n",
    "    iterator += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "df[\"hotel_name\"] = le.fit_transform(df[\"hotel_name\"].astype('str'))\n",
    "#One-hot encoding\n",
    "just_dummies = pd.get_dummies(df['hotel_name'])\n",
    "#Adding the encoded feature vectors and removing the categorical feature column\n",
    "df = pd.concat([df, just_dummies], axis=1)      \n",
    "df.drop(['hotel_name'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Removing useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['review_id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resulting data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  polarity  spam  \\\n",
      "0  Fairmont Chicago was a great choice for my wif...         1     1   \n",
      "1  Conrad Chicago it was 5:00 AM my plan just fle...         1     1   \n",
      "2  My husband and I snagged a great deal on a wee...         1     1   \n",
      "3  The Hilton in Chicago was awesome. The room wa...         1     1   \n",
      "4  My husband and I stayed at the Hyatt Regency w...         1     1   \n",
      "\n",
      "   num_of_words  avg_words_per_sent  unique_words  self_words  brand  \\\n",
      "0          73.0           10.571429          53.0    0.073171    0.0   \n",
      "1         351.0           23.466667         181.0    0.074380    0.0   \n",
      "2         135.0           17.000000          94.0    0.046667    0.0   \n",
      "3         104.0            8.750000          61.0    0.058824    0.0   \n",
      "4         114.0           14.375000          80.0    0.072581    0.0   \n",
      "\n",
      "   avg_word_length  connectors ...  10  11  12  13  14  15  16  17  18  19  \n",
      "0         4.451220         3.0 ...   0   0   0   0   0   0   0   0   0   0  \n",
      "1         3.730028        12.0 ...   0   0   0   0   0   0   0   0   0   0  \n",
      "2         4.066667         4.0 ...   0   0   0   0   0   1   0   0   0   0  \n",
      "3         3.781513         5.0 ...   0   0   0   0   0   0   0   0   0   0  \n",
      "4         4.145161         3.0 ...   0   0   0   0   0   0   0   0   0   0  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Function to word tokenize and remove stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(mess):\n",
    "    nopunc = [c for c in mess if c not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Dividing data-set to train set and test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1584, 34) (396, 34) (1584,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'spam'], \n",
    "                                                    df['spam'], test_size=0.2,random_state=1)\n",
    "print(X_train.shape, X_test.shape,y_train.shape)\n",
    "y_train = y_train.to_frame()\n",
    "y_test = y_test.to_frame()\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Transforming review text data to numerical form using TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1584, 2859)\n",
      "(1584, 34)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=4, max_df=0.7, sublinear_tf=True, use_idf=True,stop_words='english')\n",
    "train_tfidf = vectorizer.fit_transform(X_train['review']).todense()\n",
    "test_tfidf = vectorizer.transform(X_test['review']).todense()\n",
    "print(train_tfidf.shape)\n",
    "print(X_train.shape)\n",
    "X_train.drop(['review'],axis=1,inplace=True)\n",
    "X_test.drop(['review'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1584, 2859)\n",
      "(1584, 33)\n"
     ]
    }
   ],
   "source": [
    "print(train_tfidf.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "train_tfidf = pd.DataFrame(train_tfidf)\n",
    "print(type(X_train))\n",
    "print(type(train_tfidf))\n",
    "test_tfidf = pd.DataFrame(test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1893, 2892)\n"
     ]
    }
   ],
   "source": [
    "#X_train = pd.concat([X_train,train_tfidf],axis=1)\n",
    "#X_test  = pd.concat([X_test ,test_tfidf ],axis=1)\n",
    "#print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1584, 33)\n",
      "(1584, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7297979797979798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "svc = svm.SVC()\n",
    "parameters = {'kernel':('linear','rbf'), 'C':[1,10]}\n",
    "clf=GridSearchCV(svc,parameters,cv=10)\n",
    "model = clf.fit(X_train,y_train.values.ravel())\n",
    "print (\"Score:\", model.score(X_test, y_test.values.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-db35ceae3864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RdYlGn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'none'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rets' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "corr = rets.corr()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(corr, cmap='RdYlGn', interpolation='none', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr)), corr.columns, rotation='vertical')\n",
    "plt.yticks(range(len(corr)), corr.columns);\n",
    "plt.suptitle('Stock Correlations Heat Map', fontsize=15, fontweight='bold')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
